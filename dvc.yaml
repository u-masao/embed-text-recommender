stages:
  make_dataset:
    cmd: >-
      poetry run python -m src.data.make_dataset
      llm-book/livedoor-news-corpus
      data/interim/dataset.parquet
      --mlflow_run_name=pipeline
    deps:
    - src/data/make_dataset.py
    outs:
    - data/interim/dataset.parquet

  build_token_list:
    cmd: >-
      poetry run python -m src.features.build_token_list
      data/interim/dataset.parquet
      data/interim/tokens.cloudpickle
      --mlflow_run_name=pipeline
    deps:
    - src/features/build_token_list.py
    - data/interim/dataset.parquet
    outs:
    - data/interim/tokens.cloudpickle

  train_word2vec:
    cmd: >-
      poetry run python -m src.models.train_w2v_model
      data/interim/tokens.cloudpickle
      models/Word2Vec/base_dict/w2v.bin
      models/Word2Vec/base_dict/kv.bin
    deps:
    - src/models/train_w2v_model.py
    - data/interim/tokens.cloudpickle
    outs:
    - models/Word2Vec/base_dict/w2v.bin
    - models/Word2Vec/base_dict/kv.bin

  build_sentences:
    matrix:
      limit_sentences_size: ${limit_sentences_sizes}
    cmd: >-
      poetry run python -m src.features.build_sentences
      data/interim/dataset.parquet
      data/interim/sentences-limit-${item.limit_sentences_size}.parquet
      --mlflow_run_name=pipeline
      --limit_sentences_size=${item.limit_sentences_size}
    deps:
    - src/features/build_sentences.py
    - data/interim/dataset.parquet
    outs:
    - data/interim/sentences-limit-${item.limit_sentences_size}.parquet

  embed_sentences:
    matrix:
      limit_sentences_size: ${limit_sentences_sizes}
      embedding_model_string: ${embedding_model_strings}
      chunk_method: ${chunk_methods}
    cmd: >-
      poetry run python -m src.features.embed_sentences
      data/interim/sentences-limit-${item.limit_sentences_size}.parquet
      models/${item.embedding_model_string}/embeds_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle
      --mlflow_run_name=pipeline
      --embedding_model_string=${item.embedding_model_string}
      --chunk_method=${item.chunk_method}
      --batch_size=${batch_size}
    deps:
    - src/features/embed_sentences.py
    - src/models/embedding/
    - src/models/search_engine/
    - data/interim/sentences-limit-${item.limit_sentences_size}.parquet
    - models/Word2Vec/base_dict/kv.bin
    outs:
    - models/${item.embedding_model_string}/embeds_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle

  build_vector_db:
    matrix:
      limit_sentences_size: ${limit_sentences_sizes}
      embedding_model_string: ${embedding_model_strings}
      chunk_method: ${chunk_methods}
    cmd: >-
      poetry run python -m src.features.build_vector_db
      data/interim/sentences-limit-${item.limit_sentences_size}.parquet
      models/${item.embedding_model_string}/embeds_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle
      models/${item.embedding_model_string}/engine_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle
      --mlflow_run_name=pipeline
    deps:
    - src/features/build_vector_db.py
    - src/models/search_engine/
    - data/interim/sentences-limit-${item.limit_sentences_size}.parquet
    - models/${item.embedding_model_string}/embeds_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle
    outs:
    - models/${item.embedding_model_string}/engine_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle

  recommend:
    matrix:
      limit_sentences_size: ${limit_sentences_sizes}
      embedding_model_string: ${embedding_model_strings}
      chunk_method: ${chunk_methods}
    cmd: >-
      poetry run python -m src.models.recommend
      models/${item.embedding_model_string}/engine_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle
      --embedding_model_string=${item.embedding_model_string}
      --mlflow_run_name=pipeline
    deps:
    - src/models/recommend.py
    - src/models/embedding/
    - src/models/search_engine/
    - models/${item.embedding_model_string}/engine_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle
  query_simulation:
    matrix:
      limit_sentences_size: ${limit_sentences_sizes}
      embedding_model_string: ${embedding_model_strings}
      chunk_method: ${chunk_methods}
    cmd: >-
      poetry run python -m src.models.query_simulator
      models/${item.embedding_model_string}/engine_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle
      data/processed/scenario/${item.embedding_model_string}/limit-${item.limit_sentences_size}_${item.chunk_method}/
      --embedding_model_string=${item.embedding_model_string}
      --scenario_filepath=scenario.yaml
      --mlflow_run_name=pipeline
    deps:
    - src/models/query_simulator.py
    - src/models/embedding/
    - src/models/search_engine/
    - models/${item.embedding_model_string}/engine_limit-${item.limit_sentences_size}_${item.chunk_method}.cloudpickle
    - scenario.yaml
    outs:
    - data/processed/scenario/${item.embedding_model_string}/limit-${item.limit_sentences_size}_${item.chunk_method}/
