stages:
  make_dataset:
    cmd: >-
      poetry run python -m src.data.make_dataset
      llm-book/livedoor-news-corpus
      data/interim/dataset.parquet
      --mlflow_run_name=pipeline
    deps:
    - src/data/make_dataset.py
    outs:
    - data/interim/dataset.parquet

  build_sentences_and_embeddings:
    matrix:
      embedding_model_name: ${embedding_model_names}
      chunking_method: ${chunking_methods}
    cmd: >-
      poetry run python -m src.features.build_features
      data/interim/dataset.parquet
      models/${item.embedding_model_name}/sentences_${item.chunking_method}.cloudpickle
      models/${item.embedding_model_name}/embeddings_${item.chunking_method}.cloudpickle
      --mlflow_run_name=pipeline
      --model_name_or_filepath=${item.embedding_model_name}
      --chunking_method=${item.chunking_method}
      --limit_sentence_size=${limit_sentence_size}
    deps:
    - src/features/build_features.py
    - src/models/embedding/
    - src/models/search_engine/
    - data/interim/dataset.parquet
    outs:
    - models/${item.embedding_model_name}/sentences_${item.chunking_method}.cloudpickle
    - models/${item.embedding_model_name}/embeddings_${item.chunking_method}.cloudpickle

  build_vector_db:
    matrix:
      embedding_model_name: ${embedding_model_names}
      chunking_method: ${chunking_methods}
    cmd: >-
      poetry run python -m src.features.build_vector_db
      models/${item.embedding_model_name}/sentences_${item.chunking_method}.cloudpickle
      models/${item.embedding_model_name}/embeddings_${item.chunking_method}.cloudpickle
      models/${item.embedding_model_name}/engine_${item.chunking_method}.cloudpickle
      --mlflow_run_name=pipeline
    deps:
    - src/features/build_vector_db.py
    - src/models/search_engine/
    - models/${item.embedding_model_name}/sentences_${item.chunking_method}.cloudpickle
    - models/${item.embedding_model_name}/embeddings_${item.chunking_method}.cloudpickle
    outs:
    - models/${item.embedding_model_name}/engine_${item.chunking_method}.cloudpickle

  recommend:
    matrix:
      embedding_model_name: ${embedding_model_names}
      chunking_method: ${chunking_methods}
    cmd: >-
      poetry run python -m src.models.recommend
      models/${item.embedding_model_name}/engine_${item.chunking_method}.cloudpickle
      --mlflow_run_name=pipeline
      --model_name_or_filepath=${item.embedding_model_name}
    deps:
    - src/models/recommend.py
    - src/models/embedding/
    - src/models/search_engine/
    - models/${item.embedding_model_name}/engine_${item.chunking_method}.cloudpickle

  build_token_list:
    cmd: >-
      poetry run python -m src.features.build_token_list
      data/interim/dataset.parquet
      data/interim/tokens.cloudpickle
      --mlflow_run_name=pipeline
    deps:
    - src/features/build_token_list.py
    - data/interim/dataset.parquet
    outs:
    - data/interim/tokens.cloudpickle

  train_word2vec:
    cmd: >-
      poetry run python -m src.models.train_w2v_model
      data/interim/tokens.cloudpickle
      models/word2vec/w2v.bin
      models/word2vec/kv.bin
    deps:
    - src/models/train_w2v_model.py
    - data/interim/tokens.cloudpickle
    outs:
    - models/word2vec/w2v.bin
    - models/word2vec/kv.bin
